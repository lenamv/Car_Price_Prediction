{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Used Car Prices\n",
    "\n",
    "### Problem Statement\n",
    "\n",
    "The aim of this project is to create regression model to help the new car trader company determine the price of used cars.\n",
    "\n",
    "### Evaluation Metric\n",
    "Mean squared error (ùëÄùëÜùê∏)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge, RidgeCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "import pickle\n",
    "\n",
    "# Set matplotlib options\n",
    "%matplotlib inline\n",
    "color = '#1F77B4'    # Color is used in barcharts\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "fontsize=16     # Font size of a  figure title\n",
    "\n",
    "test_data = '2. Prepared Data/public_cars.csv'\n",
    "prediction_data = '2. Prepared Data/pred_cars.csv'\n",
    "df = pd.read_csv(test_data)\n",
    "df_pred = pd.read_csv(prediction_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train dataset rows: 14032 , columns: 26 \n",
      "(14032, 26)\n",
      "The test dataset rows: 7707 , columns: 25 \n",
      "(7707, 25)\n"
     ]
    }
   ],
   "source": [
    "print(\"The train dataset rows: {} , columns: {} \".format(df.shape[0],df.shape[1]))\n",
    "print(df.shape)\n",
    "\n",
    "print(\"The test dataset rows: {} , columns: {} \".format(df_pred.shape[0],df_pred.shape[1]))\n",
    "print(df_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14032 entries, 0 to 14031\n",
      "Data columns (total 26 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   manufacturer_name  14032 non-null  object \n",
      " 1   model_name         14032 non-null  object \n",
      " 2   transmission       14032 non-null  object \n",
      " 3   color              14032 non-null  object \n",
      " 4   odometer_value     14032 non-null  int64  \n",
      " 5   year_produced      14032 non-null  int64  \n",
      " 6   engine_fuel        14032 non-null  object \n",
      " 7   engine_has_gas     14032 non-null  bool   \n",
      " 8   engine_type        14032 non-null  object \n",
      " 9   engine_capacity    14027 non-null  float64\n",
      " 10  body_type          14032 non-null  object \n",
      " 11  has_warranty       14032 non-null  bool   \n",
      " 12  state              14032 non-null  object \n",
      " 13  drivetrain         14031 non-null  object \n",
      " 14  feature_0          14031 non-null  object \n",
      " 15  feature_1          14031 non-null  object \n",
      " 16  feature_2          14031 non-null  object \n",
      " 17  feature_3          14031 non-null  object \n",
      " 18  feature_4          14031 non-null  object \n",
      " 19  feature_5          14031 non-null  object \n",
      " 20  feature_6          14031 non-null  object \n",
      " 21  feature_7          14031 non-null  object \n",
      " 22  feature_8          14031 non-null  object \n",
      " 23  feature_9          14031 non-null  object \n",
      " 24  duration_listed    14031 non-null  float64\n",
      " 25  price_usd          14031 non-null  float64\n",
      "dtypes: bool(2), float64(3), int64(2), object(19)\n",
      "memory usage: 2.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: (14032, 26)\n",
      "Dropped duplicated rows : 8\n",
      "Dataset: (14024, 26)\n"
     ]
    }
   ],
   "source": [
    "# Check duplicated rows\n",
    "duplicated_rows = df.duplicated().sum()\n",
    "print('Dataset: {}'.format(df.shape))\n",
    "\n",
    "# Drop duplicated rows\n",
    "if duplicated_rows != 0:\n",
    "    df.drop_duplicates(inplace=True)\n",
    "print('Dropped duplicated rows : {}'.format(duplicated_rows))\n",
    "print('Dataset: {}'.format(df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values: 18\n",
      "\n",
      "Dropped rows with missing price: 1 \n",
      "Dataset: (14023, 26)\n",
      "\n",
      "Missing values: 5\n"
     ]
    }
   ],
   "source": [
    "# Find missing values \n",
    "print(f'Missing values: {df.isnull().sum().sum()}')\n",
    "\n",
    "isnull_filter = df['price_usd'].isnull()\n",
    "\n",
    "# Drop the row with missing price\n",
    "missing_price = len(df[isnull_filter].index)\n",
    "print('\\nDropped rows with missing price: {} '.format(missing_price))\n",
    "df.drop(df[isnull_filter].index, inplace=True)\n",
    "df = df.reset_index(drop=True)\n",
    "print('Dataset: {}'.format(df.shape))\n",
    "\n",
    "# Find missing values \n",
    "print('\\nMissing values: {}'.format(df.isnull().sum().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: (14023, 26)\n",
      "Dropped rows with electric cars: 5 \n",
      "\n",
      "0.995 quantile: 37885.03119999992\n",
      "Drop prices over the 99.5% percentile: 71\n",
      "Dataset: (13948, 26)\n"
     ]
    }
   ],
   "source": [
    "# Drop electric cars\n",
    "electric_cars = df['engine_type'] == 'electric'\n",
    "electric = df[electric_cars]\n",
    "\n",
    "# Remove prices over the 99.5% percentile\n",
    "quantile = df['price_usd'].quantile(0.995)\n",
    "price_quantile = df['price_usd'] > quantile\n",
    "price = df[price_quantile]\n",
    "\n",
    "outliers = df[(electric_cars | price_quantile )]\n",
    "\n",
    "# Save the rows with outliers to csv file\n",
    "fl = \"4. Analysis/used_car_prices_outliers.csv\"\n",
    "outliers.to_csv(fl, index=False)\n",
    "\n",
    "print('Dataset: {}'.format(df.shape))\n",
    "df.drop( outliers.index, inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "print('Dropped rows with electric cars: {} '.format(len(electric)))\n",
    "print('\\n0.995 quantile: {}'.format(quantile))\n",
    "print('Drop prices over the 99.5% percentile: {}'.format(len(price)))\n",
    "print('Dataset: {}'.format(df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: (13948, 26)\n",
      "Drop outliers :13\n",
      "Dataset: (13935, 26)\n"
     ]
    }
   ],
   "source": [
    "# Drop extreme outliers\n",
    "\n",
    "min_price = 100\n",
    "mask_price = df['price_usd']<100\n",
    "\n",
    "max_odometer_value = 500000\n",
    "max_price = 30000\n",
    "mask_odometer_value =  (df['odometer_value'] > max_odometer_value) & (df['price_usd'] > max_price)\n",
    "\n",
    "min_year_produced = 1970\n",
    "max_price = 14000\n",
    "mask_produced_price = (df['year_produced'] < min_year_produced) & (df['price_usd'] > max_price)\n",
    "\n",
    "min_year_produced = df['year_produced'].min()\n",
    "mask_year_produced_min = (df['year_produced'] == min_year_produced)\n",
    "\n",
    "min_engine_capacity = 0.8\n",
    "max_engine_capacity = df['engine_capacity'].max()\n",
    "mask_engine = (df['engine_capacity']<min_engine_capacity) | (df['engine_capacity'] == max_engine_capacity)\n",
    "\n",
    "max_duration_listed = df['duration_listed'].max()\n",
    "mask_duration_listed = (df['duration_listed'] == max_duration_listed)\n",
    "\n",
    "outliers = df[(mask_price | mask_odometer_value | mask_produced_price | mask_year_produced_min | mask_engine | mask_duration_listed)]\n",
    "#outliers\n",
    "\n",
    "# Save the rows with extreme outliers to csv file\n",
    "fl = \"4. Analysis/used_car_prices_extreme_outliers.csv\"\n",
    "outliers.to_csv(fl, index=False)\n",
    "\n",
    "print(\"Dataset: {}\".format(df.shape))\n",
    "df.drop( outliers.index, inplace=True )\n",
    "df.reset_index(drop=True)\n",
    "print('Drop outliers :{}'.format(len(outliers)))\n",
    "print(\"Dataset: {}\".format(df.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 'name' variable to combine manufacture and model names\n",
    "columns_strip = ['manufacturer_name', 'model_name']\n",
    "# Delete extra space in strings\n",
    "for column in columns_strip:\n",
    "    df[column] = df[column].apply(lambda x: x.strip())\n",
    "# Combine manufacture and model names    \n",
    "df['name'] = df['manufacturer_name'] + ' ' + df['model_name']\n",
    "\n",
    "# Create a feature that represents mileage per year\n",
    "df['odometer_value/year'] = round(df['odometer_value']/(2020 - df['year_produced']))\n",
    "# Create a feature how old is a car\n",
    "df['year'] = 2020 - df['year_produced']\n",
    "\n",
    "# Reduce the number of car model names\n",
    "# Set a limit of rare car occurrence\n",
    "car_total = 6\n",
    "# Count a number of car names and convert the result to a dataframe\n",
    "car_models = pd.DataFrame(df['name'].value_counts())\n",
    "# Get a list of rare car names\n",
    "car_models = car_models[car_models['name'] < car_total].index\n",
    "# create a new category'other' for rare car model names\n",
    "df['name'] = df['name'].apply(lambda x: 'other' if x in car_models else x)\n",
    "\n",
    "# Create features to reduce a number of categories\n",
    "hybrid ='hybrid_or_electric'\n",
    "df['engine_fuel'] = df['engine_fuel'].replace({'hybrid-petrol':hybrid,'hybrid-diesel':hybrid,'electric':hybrid})\n",
    "\n",
    "\n",
    "# Create a list of unnamed features\n",
    "features_list = ['feature_0','feature_1', 'feature_2', 'feature_3', 'feature_4', 'feature_5', 'feature_6', 'feature_7', 'feature_8', 'feature_9']\n",
    "# Count a total number of unnamed features for a car\n",
    "df['other_features']=df[features_list].sum(axis=1)\n",
    "\n",
    "# Round car prices\n",
    "df['price_usd'] = df['price_usd'].apply(lambda x: round(x,-2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['manufacturer_name', 'model_name', 'transmission', 'color',\n",
       "       'odometer_value', 'year_produced', 'engine_fuel', 'engine_has_gas',\n",
       "       'engine_type', 'engine_capacity', 'body_type', 'has_warranty', 'state',\n",
       "       'drivetrain', 'feature_0', 'feature_1', 'feature_2', 'feature_3',\n",
       "       'feature_4', 'feature_5', 'feature_6', 'feature_7', 'feature_8',\n",
       "       'feature_9', 'duration_listed', 'price_usd', 'name',\n",
       "       'odometer_value/year', 'year', 'other_features'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: (13935, 17)\n"
     ]
    }
   ],
   "source": [
    "# Define predictor and target variables\n",
    "features =[ 'manufacturer_name', 'has_warranty', 'state', 'drivetrain', 'transmission', 'name',\n",
    "           'odometer_value', 'odometer_value/year', 'year',  'engine_fuel','color',\n",
    "           'duration_listed', 'body_type', 'engine_capacity', 'other_features', 'feature_0'\n",
    "          ]\n",
    "\n",
    "target = 'price_usd'\n",
    "\n",
    "# Create the dataset to fit a model\n",
    "data = df[features+ [target]].copy()\n",
    "print('Dataset: {}'.format(data.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric features: ['odometer_value', 'odometer_value/year', 'year', 'duration_listed', 'engine_capacity', 'other_features']\n",
      "Categorical features: ['manufacturer_name', 'has_warranty', 'state', 'drivetrain', 'transmission', 'name', 'engine_fuel', 'color', 'body_type', 'feature_0']\n"
     ]
    }
   ],
   "source": [
    "# Copy the initial dataset before transformation\n",
    "df_origin = data.copy()\n",
    "\n",
    "# Create features and target from the data set\n",
    "X = data.drop(target ,axis=1)\n",
    "y = data[target]\n",
    "\n",
    "# Numeric data types\n",
    "numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "\n",
    "# Print numeric features\n",
    "numeric_features = X.select_dtypes(numerics).columns.tolist()\n",
    "print('Numeric features: {}'.format(numeric_features))\n",
    "\n",
    "\n",
    "# Applies Power Transformer using Yeo-Johnson transformation to numeric columns \n",
    "numeric_power = ['odometer_value',  'odometer_value/year', 'duration_listed']\n",
    "\n",
    "numeric_power_transformer = Pipeline(steps=\n",
    "                                    [('imputer', SimpleImputer(strategy='constant', fill_value=0)),\n",
    "                                     ('power', PowerTransformer(method='yeo-johnson')),\n",
    "                                     ('scaler', StandardScaler())\n",
    "                                    ])\n",
    "\n",
    "# Applies Quantile Transformer to numeric columns \n",
    "numeric_quantile = ['engine_capacity', 'year', 'other_features']\n",
    "\n",
    "numeric_quantile_transformer = Pipeline(steps=\n",
    "                                    [('imputer', SimpleImputer(strategy='constant', fill_value=0)),\n",
    "                                     ('quantile', QuantileTransformer(n_quantiles=100, output_distribution='normal')),\n",
    "                                     ('scaler', StandardScaler())\n",
    "                                    ])\n",
    "\n",
    "\n",
    "# Print categorical features\n",
    "categorical_features = X.select_dtypes([np.object,np.bool]).columns.tolist()\n",
    "print('Categorical features: {}'.format(categorical_features))\n",
    "\n",
    "# Transform categorical columns using OneHotEncoder\n",
    "categorical_transformer = Pipeline(steps=\n",
    "                                    [('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "                                     ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "                                    ])\n",
    "# Create ColumnTransformer to perform different transformations for different columns of the data\n",
    "preprocessor = ColumnTransformer(transformers=\n",
    "                                 [('num_power', numeric_power_transformer, numeric_power),\n",
    "                                  ('num_qt', numeric_quantile_transformer, numeric_quantile),\n",
    "                                  ('cat', categorical_transformer, categorical_features)\n",
    "                                 ])\n",
    "\n",
    "# Reshape target variable\n",
    "y = np.array(y).reshape(-1,1)\n",
    "\n",
    "# Split the data into training and testing datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "# Transform the target variable\n",
    "power_tr = PowerTransformer(method='yeo-johnson')\n",
    "power_tr.fit(y_train)\n",
    "\n",
    "y_train = power_tr.transform(y_train)\n",
    "y_test = power_tr.transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR(C=1)\n",
      "Score: 0.9190084232543707\n",
      "MSE: -0.09049174643940402\n"
     ]
    }
   ],
   "source": [
    "######################################### SVR model ######################################\n",
    "# Create an instance of a model\n",
    "model = SVR(C=1)\n",
    "print(model)\n",
    "\n",
    "# Define preprocessing pipeline\n",
    "pipe = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                       ('model', model)])  \n",
    "\n",
    "y_train = y_train.ravel()\n",
    "y_test = y_test.ravel()\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "score = pipe.score(X_test, y_test)\n",
    "print('Score: {}'.format(score))\n",
    "\n",
    "mse = cross_val_score(pipe, X_test, y_test, cv=10, scoring ='neg_mean_squared_error' ).mean()\n",
    "print('MSE: {}'.format(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file 5. Insights/Models/used_car_prices_model.pickle is saved.\n"
     ]
    }
   ],
   "source": [
    "# Save the pipeline\n",
    "model_path = '5. Insights/Models/used_car_prices_model.pickle'\n",
    "with open(model_path, 'wb') as f:\n",
    "    pickle.dump(pipe, f)\n",
    "\n",
    "print('The file {} is saved.'.format(model_path))\n",
    "\n",
    "# Save the PorewTransformer object for the inverse target transformation\n",
    "transformer_path = '5. Insights/Models/used_car_prices_target_transformation.pickle'\n",
    "with open(transformer_path, 'wb') as f:\n",
    "    pickle.dump(power_tr, f)\n",
    "print('The file {} is saved.'.format(transformer_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ptrediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression model SVR(C=1) is loaded.\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "prediction_data = '2. Prepared Data/pred_cars.csv'\n",
    "df = pd.read_csv(prediction_data)\n",
    "\n",
    "# Load a model from a file\n",
    "model_path = '5. Insights/Models/used_car_prices_model.pickle'\n",
    "with open(model_path, 'rb') as f:\n",
    "    regression_model_loaded = pickle.load(f)\n",
    "print('Regression model {} is loaded.'.format(regression_model_loaded))\n",
    "\n",
    "# Load the PorewTransformer object for the inverse target transformation\n",
    "transformer_path = '5. Insights/Models/used_car_prices_target_transformation.pickle'\n",
    "with open(transformer_path, 'rb') as f:\n",
    "    transformer_loaded = pickle.load(f)\n",
    "print('Transformer {} is loaded.'.format(transformer_loaded))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7707 entries, 0 to 7706\n",
      "Data columns (total 25 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   manufacturer_name  7707 non-null   object \n",
      " 1   model_name         7707 non-null   object \n",
      " 2   transmission       7707 non-null   object \n",
      " 3   color              7707 non-null   object \n",
      " 4   odometer_value     7707 non-null   int64  \n",
      " 5   year_produced      7707 non-null   int64  \n",
      " 6   engine_fuel        7707 non-null   object \n",
      " 7   engine_has_gas     7707 non-null   bool   \n",
      " 8   engine_type        7707 non-null   object \n",
      " 9   engine_capacity    7705 non-null   float64\n",
      " 10  body_type          7707 non-null   object \n",
      " 11  has_warranty       7707 non-null   bool   \n",
      " 12  state              7707 non-null   object \n",
      " 13  drivetrain         7707 non-null   object \n",
      " 14  feature_0          7707 non-null   bool   \n",
      " 15  feature_1          7707 non-null   bool   \n",
      " 16  feature_2          7707 non-null   bool   \n",
      " 17  feature_3          7707 non-null   bool   \n",
      " 18  feature_4          7707 non-null   bool   \n",
      " 19  feature_5          7707 non-null   bool   \n",
      " 20  feature_6          7707 non-null   bool   \n",
      " 21  feature_7          7707 non-null   bool   \n",
      " 22  feature_8          7707 non-null   bool   \n",
      " 23  feature_9          7707 non-null   bool   \n",
      " 24  duration_listed    7707 non-null   int64  \n",
      "dtypes: bool(12), float64(1), int64(3), object(9)\n",
      "memory usage: 873.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 'name' variable to combine manufacture and model names\n",
    "columns_strip = ['manufacturer_name', 'model_name']\n",
    "# Delete extra space in strings\n",
    "for column in columns_strip:\n",
    "    df[column] = df[column].apply(lambda x: x.strip())\n",
    "# Combine manufacture and model names    \n",
    "df['name'] = df['manufacturer_name'] + ' ' + df['model_name']\n",
    "\n",
    "# Create a feature that represents mileage per year\n",
    "df['odometer_value/year'] = round(df['odometer_value']/(2020 - df['year_produced']))\n",
    "# Create a feature how old is a car\n",
    "df['year'] = 2020 - df['year_produced']\n",
    "\n",
    "# Reduce the number of car model names\n",
    "# Set a limit of rare car occurrence\n",
    "car_total = 6\n",
    "# Count a number of car names and convert the result to a dataframe\n",
    "car_models = pd.DataFrame(df['name'].value_counts())\n",
    "# Get a list of rare car names\n",
    "car_models = car_models[car_models['name'] < car_total].index\n",
    "# Create a new category'other' for rare car model names\n",
    "df['name'] = df['name'].apply(lambda x: 'other' if x in car_models else x)\n",
    "\n",
    "# Create features to reduce a number of categories\n",
    "hybrid ='hybrid_or_electric'\n",
    "df['engine_fuel'] = df['engine_fuel'].replace({'hybrid-petrol':hybrid,'hybrid-diesel':hybrid,'electric':hybrid})\n",
    "\n",
    "# Create a list of unnamed features\n",
    "features_list = ['feature_0','feature_1', 'feature_2', 'feature_3', 'feature_4', 'feature_5', 'feature_6', 'feature_7', 'feature_8', 'feature_9']\n",
    "# Count a total number of unnamed features for a car\n",
    "df['other_features']=df[features_list].sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction of car prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.98057763, -0.79509045, -0.0357562 , ..., -0.36707498,\n",
       "        1.38403971, -0.71307949])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make prediction using the pipeline\n",
    "prediction = regression_model_loaded.predict(df[features])\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted</th>\n",
       "      <th>Predicted rounded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1590.984824</td>\n",
       "      <td>1600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1975.472461</td>\n",
       "      <td>2000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4415.713651</td>\n",
       "      <td>4400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10066.528876</td>\n",
       "      <td>10100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5480.357270</td>\n",
       "      <td>5500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7702</th>\n",
       "      <td>2532.449728</td>\n",
       "      <td>2500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7703</th>\n",
       "      <td>17408.760063</td>\n",
       "      <td>17400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7704</th>\n",
       "      <td>3155.158377</td>\n",
       "      <td>3200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7705</th>\n",
       "      <td>15255.877648</td>\n",
       "      <td>15300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7706</th>\n",
       "      <td>2167.929072</td>\n",
       "      <td>2200.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7707 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Predicted  Predicted rounded\n",
       "0      1590.984824             1600.0\n",
       "1      1975.472461             2000.0\n",
       "2      4415.713651             4400.0\n",
       "3     10066.528876            10100.0\n",
       "4      5480.357270             5500.0\n",
       "...            ...                ...\n",
       "7702   2532.449728             2500.0\n",
       "7703  17408.760063            17400.0\n",
       "7704   3155.158377             3200.0\n",
       "7705  15255.877648            15300.0\n",
       "7706   2167.929072             2200.0\n",
       "\n",
       "[7707 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform predicted price to get the rounded car price in dollars\n",
    "y_predict_price = transformer_loaded.inverse_transform(prediction.reshape(-1,1))\n",
    "# Round car price to hundred\n",
    "y_predict_price_round = np.round(y_predict_price,-2)\n",
    "# Create a dataframe with results\n",
    "results = pd.DataFrame( {'Predicted':y_predict_price.reshape(-1),\n",
    "                         'Predicted rounded':y_predict_price_round.reshape(-1)},\n",
    "                          index=df.index)\n",
    "\n",
    "# Form a dataframe with car information and predicted prices\n",
    "prediction_results = df.join(results)\n",
    "\n",
    "# Save car information and predicted prices to csv file\n",
    "fl = \"5. Insights/Prediction/used_car_prices_prediction_data_predicted_price.csv\"\n",
    "prediction_results.to_csv(fl, index=False)\n",
    "\n",
    "# Save predicted prices to csv file\n",
    "fl = \"5. Insights/Prediction/used_car_prices_predicted_price.csv\"\n",
    "results.to_csv(fl, index=False)\n",
    "\n",
    "# Predicted car prices\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
